---
title: "The logistic regression on loan Report"
date: "July, 2019"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos =  "h")
knitr::opts_knit$set(root.dir = "../")

# loading required libraries
library(rmarkdown)
library(dplyr)
library(tidyr)
library(forcats)
library(lubridate)
library(tinytex)
library(feather)
library(corrplot)
library(mctest)
library(caret)
library(hmeasure)
library(pROC)
library(rms)
library(knitr)
library(ggplot2)
library(ggcorrplot)
library(ggthemes)

```

```{r scripts, include=FALSE}
# loading required steps before performing the analysis
source("./scripts/step_01_create_functions.R")
source("./scripts/step_02_data_ingestion.R")
source("./scripts/step_03_data_cleaning.R")
source("./scripts/step_04_label_translation.R")
source("./scripts/step_05_data_enhancement.R")
```

# Objective

The goal of this report is trying to fit a logistic regression model on Loan data aiming to predict the probability of delinquency for each contract.

# Task description

## Dataset preparation

Using the vanilla transaction dataset, we calculated several derived variables for each account.

First, we calculated an additional table with the current account balance and average account balance of each account.

Later on, we calculated another auxiliary table that contains the proportion of each kind of transaction (k_symbol) for each account. The idea of these variable is to capture the spend pattern of each client.

Finally, we combine the 682 Loan Contracts observations with client, district, credit card and the auxiliary tables we calculated early.

```{r data_prep, echo=FALSE, include=FALSE}

temp <- left_join(loan, disposition, by = c('account_id', 'type')) %>% 
  left_join(client, by = 'client_id') %>%
  left_join(district, by = 'district_id') %>% 
  left_join(creditcard, by = 'disp_id') %>% 
  left_join(account_balance, by = 'account_id') %>% 
  left_join(account_transaction_pattern, by = 'account_id') %>% 
  mutate(card_age_month = (issued %--% 
                             make_date(1998, 12, 31)) / months(1),
         last_transaction_age_days = ((last_transaction_date.y %--% 
                                         make_date(1998, 12, 31)) / days(1)),
         has_card = ifelse(type.y == 'no card', 0, 1)) %>% 
  dplyr::select(c("amount.x", "duration", "payments", "status", "defaulter", 
                  "contract_status", "gender", "age", "district_name", 
                  "region", "no_of_inhabitants", 
                  "no_of_municip_inhabitants_less_499", 
                  "no_of_municip_500_to_1999", "no_of_municip_2000_to_9999", 
                  "no_of_municip_greater_10000", "no_of_cities", 
                  "ratio_of_urban_inhabitants", 
                  "average_salary", "unemploymant_rate_1995", 
                  "unemploymant_rate_1996", 
                  "no_of_enterpreneurs_per_1000_inhabitants", 
                  "no_of_commited_crimes_1995", 
                  "no_of_commited_crimes_1996", "type.y", 
                  "card_age_month","account_balance", 
                  "avg_balance","transaction_count", "amount.y", 
                  "last_transaction_age_days", "prop_old_age_pension", 
                  "prop_insurance_payment", 
                  "prop_sanction_interest","prop_household", 
                  "prop_statement", "prop_interest_credited", 
                  "prop_loan_payment", "prop_other", "has_card"))

colnames(temp) <- c("x_loan_amount", "x_loan_duration", "x_loan_payments", 
                    "x_loan_status", "y_loan_defaulter", "x_loan_contract_status",
                    "x_client_gender", "x_client_age", 
                    "x_district_name", "x_region", 
                    "x_no_of_inhabitants", "x_no_of_municip_inhabitants_less_499", 
                    "x_no_of_municip_500_to_1999", "x_no_of_municip_2000_to_9999", 
                    "x_no_of_municip_greater_10000", "x_no_of_cities", 
                    "x_ratio_of_urban_inhabitants", 
                    "x_average_salary", "x_unemploymant_rate_1995", 
                    "x_unemploymant_rate_1996", 
                    "x_no_of_enterpreneurs_per_1000_inhabitants", 
                    "x_no_of_commited_crimes_1995", 
                    "x_no_of_commited_crimes_1996", "x_card_type", 
                    "x_card_age_month","x_account_balance", 
                    "x_avg_account_balance","x_transaction_count", 
                    "x_transaction_amount", "x_last_transaction_age_days", 
                    "x_prop_old_age_pension", "x_prop_insurance_payment", 
                    "x_prop_sanction_interest","x_prop_household","x_prop_statement",
                    "x_prop_interest_credited", "x_prop_loan_payment", "x_prop_other",
                    "x_has_card")

temp <- dplyr::select(temp, y_loan_defaulter, everything())

temp$x_card_type = ifelse(is.na(temp$x_card_type), 'no card', 
                          as.character(temp$x_card_type))

temp$x_has_card = ifelse(temp$x_card_type == 'no card', 0, 1)

temp$x_card_age_month = ifelse(is.na(temp$x_card_age_month), 0, 
                               temp$x_card_age_month)

temp$y_loan_defaulter = as.numeric(temp$y_loan_defaulter)

```

We ended up having a data set with 39 variables.

```{r variables}
kable(tibble(variables = names(temp)))
```

## Variable selection

From this dataset, we excluded 6 variables that are redundant, shows no variability on the 682 Loan contract observations or have no applicability for the exercise:

- **x_prop_old_age_pension** (no variation on selected sample);
- **x_district_name** (sample have not enough variability to fit a model);
- **x_region** (sample have not enough variability to fit a model);
- **x_loan_status** (redundant);
- **x_loan_contract_status** (redundant); 
- **x_prop_sanction_interest** (seems not to be valid for this analysis, as the reason for interest payment in the account is exactly the delinquency in the observation contact itself).

```{r remove_variables_1}
temp <- dplyr::select(temp, -c(x_prop_old_age_pension, 
                               x_district_name, 
                               x_region, 
                               x_loan_status, 
                               x_loan_contract_status, 
                               x_prop_sanction_interest))
```

## Investigating Multicollinearity

With the remaining variables we ran a multicollinearity test to identify additional variables to drop from the model specification.

```{r check_correl, out.width = '100%'}

vars.quant <- select_if(temp, is.numeric)
VIF <- imcdiag(vars.quant, temp$y_loan_defaulter)

VIF_Table_Before <- tibble(variable = names(VIF$idiags[,1]),
                    VIF = VIF$idiags[,1]) %>% 
             arrange(desc(VIF))

kable(VIF_Table_Before)
```

```{r plot_correl, out.width = '100%', echo=FALSE}
ggplot(VIF_Table_Before, aes(x = fct_reorder(variable, VIF), y = log(VIF), label = round(VIF, 2))) + 
  geom_point(stat='identity', fill="black", size=15)  +
  geom_segment(aes(y = 0, 
                   yend = log(VIF), 
                   xend = variable), 
               color = "black") +
  geom_text(color="white", size=4) +
  geom_hline(aes(yintercept = log(5)), color = 'red', size = 2) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  coord_flip() +
  theme_economist() +
  theme(legend.position = 'none', 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  labs(x = 'Variable',
       y = NULL,
       title = 'Variance Inflation Factor',
       subtitle="Checking for multicolinearity in X's variables.
       Variables with VIF more than 4 will 
       be droped from the model")
```

We decided to exclude any variable with a VIF greater than 5.

Below variables were excluded based on the multicollinear presence on them.

- **x_prop_insurance_payment**;
- **x_prop_household**;
- **x_prop_statement** ;
- **x_prop_loan_payment**; 
- **x_prop_other**;
- **x_no_of_inhabitants**; 
- **x_no_of_commited_crimes_1996**;
- **x_transaction_amount**;
- **x_transaction_count**;
- **x_unemploymant_rate_1996**; 
- **x_unemploymant_rate_1995**;
- **x_average_salary**;
- **x_no_of_cities**.

```{r remove_variables_2}
temp <- dplyr::select(temp, -c(x_prop_insurance_payment,
                               x_prop_household,
                               x_prop_statement,
                               x_prop_loan_payment,
                               x_prop_other,
                               x_no_of_inhabitants,
                               x_no_of_commited_crimes_1996,
                               x_transaction_amount,
                               x_transaction_count,
                               x_unemploymant_rate_1996,
                               x_unemploymant_rate_1995,
                               x_average_salary,
                               x_no_of_cities))

loan_reg_dataset <- temp
```

Here is the final correlation matrix we got:

```{r check_correl_2, out.width = '100%', echo=FALSE}
vars.quant <- select_if(loan_reg_dataset, is.numeric)

VIF <- imcdiag(vars.quant, loan_reg_dataset$y_loan_defaulter)

VIF_Table_After <- tibble(variable = names(VIF$idiags[,1]),
                    VIF = VIF$idiags[,1]) %>% 
  arrange(desc(VIF))

kable(VIF_Table_After)
```

```{r plot_correl_2, out.width = '100%', echo=FALSE}
ggplot(VIF_Table_After, aes(x = fct_reorder(variable, VIF), y = log(VIF), label = round(VIF, 2))) + 
  geom_point(stat='identity', fill="black", size=15)  +
  geom_segment(aes(y = 0, 
                   yend = log(VIF), 
                   xend = variable), 
               color = "black") +
  geom_text(color="white", size=4) +
  geom_hline(aes(yintercept = log(5)), color = 'red', size = 2) +
  scale_y_continuous(labels = NULL, breaks = NULL) +
  coord_flip() +
  theme_economist() +
  theme(legend.position = 'none', 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  labs(x = 'Variable',
       y = NULL,
       title = 'Variance Inflation Factor',
       subtitle="Checking for multicolinearity in X's variables.
       Variables with VIF more than 5 will 
       be droped from the model")

cor_mtx <- cor(vars.quant)

ggcorrplot(cor_mtx, hc.order = TRUE, 
           type = "lower", 
           lab = TRUE, 
           lab_size = 3, 
           method="circle", 
           colors = c("tomato2", "white", "springgreen3"), 
           title="Correlation Matrix of Loan Dataset", 
           ggtheme=theme_bw)
```

## Sample split into Test and Training Data

The available data in Loan Dataset is split into Train and Testing data on the following proportion:

- **Train Dataset** (70% xx obs);
- **Test Dataset** (30% xx obs).

```{r split_sample}
set.seed(12345)
index <- caret::createDataPartition(loan_reg_dataset$y_loan_defaulter, 
                                    p= 0.7,list = FALSE)

data.train <- loan_reg_dataset[index, ]
data.test  <- loan_reg_dataset[-index,]

kable(prop.table(table(loan_reg_dataset$y_loan_defaulter)))
kable(prop.table(table(data.train$y_loan_defaulter)))
kable(prop.table(table(data.test$y_loan_defaulter)))
```

Both datasets keep the same proportion for the explained variable around 11%.

## Fit the logistic model 

With the final cleaned dataset, we got from below steps we fit our Logistic Regression Y_loan_defaulter on all x variables.

```{r fit_model_1}
model_1 <- glm(data = data.train, formula = y_loan_defaulter ~ .,
                 family= binomial(link='logit'))

summary(model_1)
```

Alternatively we fit a second model only with variables statistically significant p-value less than 10%.

```{r fit_model_2}
model_2 <- glm(data = data.train, formula = y_loan_defaulter ~ x_loan_amount +
                 x_loan_duration + x_has_card + x_prop_interest_credited,
                 family= binomial(link='logit'))

summary(model_2)
```

In the next step we will compare how each model performed.

# Evaluating the model performance

We started this step by making predictions using our model on the X's variables in our Train and Test datasets.

```{r predict}
glm.prob.train.1 <- predict(model_1, type = "response")
glm.prob.test.1 <- predict(model_1, newdata = data.test, type= "response")

glm.prob.train.2 <- predict(model_2, type = "response")
glm.prob.test.2 <- predict(model_2, newdata = data.test, type= "response")
```

We then evaluate the metrics in the model for Train and Test data:

```{r measure}
glm.train.1 <- HMeasure(data.train$y_loan_defaulter, glm.prob.train.1)
glm.test.1  <- HMeasure(data.test$y_loan_defaulter, glm.prob.test.1)

kable(glm.train.1$metrics)
kable(glm.test.1$metrics)

glm.train.2 <- HMeasure(data.train$y_loan_defaulter, glm.prob.train.2)
glm.test.2 <- HMeasure(data.test$y_loan_defaulter, glm.prob.test.2)

kable(glm.train.2$metrics)
kable(glm.test.2$metrics)
```

Then, we look a boxplot chart to see how well our model split the observation into our explained variable:

-**Model 1:**
```{r boxplot_1, out.width = '100%', echo=FALSE}
boxplot(glm.prob.test.1 ~ data.test$y_loan_defaulter,
        col= c("red", "green"), 
        horizontal= T,
        xlab = 'Probability Prediction',
        ylab = 'Loan Defaulter')
```

-**Model 2:**
```{r boxplot_2, out.width = '100%', echo=FALSE}
boxplot(glm.prob.test.2 ~ data.test$y_loan_defaulter,
        col= c("red", "green"), 
        horizontal= T,
        xlab = 'Probability Prediction',
        ylab = 'Loan Defaulter')
```

Then we plot the ROC(Receiver Operator Characteristic Curve) of the model:

```{r roC, out.width = '100%', echo=FALSE}
roc_1 <- roc(data.test$y_loan_defaulter, glm.prob.test.1)
roc_2 <- roc(data.test$y_loan_defaulter, glm.prob.test.2)

y1 <- roc_1$sensitivities
x1 <- 1-roc_1$specificities

y2 <- roc_2$sensitivities
x2 <- 1-roc_2$specificities

plot(x1, y1,  type="n",
     xlab = "False Positive Rate (Specificities)", 
     ylab= "True Positive Rate (Sensitivities)")

lines(x1, y1,lwd=3,lty=1, col="red") 
lines(x2, y2,lwd=3,lty=1, col="blue")

abline(0,1, lty=2)
```

Finally we look at the general model accuracy:

-**Model 1:**

```{r accuracy_1}
fitted.results.1 <- ifelse(glm.prob.test.1 > 0.5,1,0)

misClasificError <- mean(fitted.results.1 != data.test$y_loan_defaulter)
print(paste('General Accuracy: ', round(((1 - misClasificError) * 100),2), '%'))
```

-**Model 2:**

```{r accuracy_2}
fitted.results.2 <- ifelse(glm.prob.test.2 > 0.5,1,0)

misClasificError <- mean(fitted.results.2 != data.test$y_loan_defaulter)
print(paste('General Accuracy: ', round(((1 - misClasificError) * 100),2), '%'))
```