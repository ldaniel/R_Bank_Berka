---
title: "Logistic Regression on Loan Dataset"
date: "July, 2019"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos =  "h")
knitr::opts_knit$set(root.dir = "../")

# loading required libraries
library(rmarkdown)
library(dplyr)
library(ggplot2)
library(tidyr)
library(lubridate)
library(ggalluvial)
library(stringr)
library(VIM)
library(psych)
library(ggthemes)
library(tinytex)
library(leaflet)
library(feather)
library(corrplot)
library(knitr)

```

```{r include=FALSE}
# loading required steps before performing the analysis
source("./scripts/step_01_create_functions.R")
source("./scripts/step_02_data_ingestion.R")
source("./scripts/step_03_data_cleaning.R")
source("./scripts/step_04_label_translation.R")
source("./scripts/step_05_data_enhancement.R")
```

# Objective
The objective of this session is to try to fit a logistic regression model on Loan data aiming to predit the probability of delinquency for each contract.

# Task descripion

## Step 01 - Dataset Preparation
Using the vanilla transaction dataset we calculated several derived variables for each account.

First we calculated an additional table with the current account balance and average account balance of each account.

Later we calculated another auxiliary table that contains the proportion of each kind of transaction (k_symbol) for each account. The idea os these variable is to capture the spend pattern of each client.

Finnaly we combine the 682 Loan Contracts observations with client, district, credit card and the auxiliary tables we calculated early.

```{r echo=FALSE}

temp <- left_join(loan, disposition, by = c('account_id', 'type')) %>% 
  left_join(client, by = 'client_id') %>%
  left_join(district, by = 'district_id') %>% 
  left_join(creditcard, by = 'disp_id') %>% 
  left_join(account_balance, by = 'account_id') %>% 
  left_join(account_transaction_pattern, by = 'account_id') %>% 
  mutate(card_age_month = (issued %--% 
                             make_date(1998, 12, 31)) / months(1),
         last_transaction_age_days = ((last_transaction_date.y %--% 
                                         make_date(1998, 12, 31)) / days(1))) %>% 
  dplyr::select(c("amount.x", "duration", "payments", "status", "defaulter", "contract_status",
           "gender", "age", "district_name", "region", 
           "no_of_inhabitants", "no_of_municip_inhabitants_less_499", 
           "no_of_municip_500_to_1999", "no_of_municip_2000_to_9999", 
           "no_of_municip_greater_10000", "no_of_cities", "ratio_of_urban_inhabitants", 
           "average_salary", "unemploymant_rate_1995", "unemploymant_rate_1996", 
           "no_of_enterpreneurs_per_1000_inhabitants", "no_of_commited_crimes_1995", 
           "no_of_commited_crimes_1996", "type.y", "card_age_month","account_balance", 
           "avg_balance","transaction_count", "amount.y", 
           "last_transaction_age_days", "prop_old_age_pension", "prop_insurance_payment", 
           "prop_sanction_interest","prop_household", 
           "prop_statement", "prop_interest_credited", 
           "prop_loan_payment", "prop_other"))

colnames(temp) <- c("x_loan_amount", "x_loan_duration", "x_loan_payments", "x_loan_status", 
                    "y_loan_defaulter", "x_loan_contract_status",
                    "x_client_gender", "x_client_age", "x_district_name", "x_region", 
                    "x_no_of_inhabitants", "x_no_of_municip_inhabitants_less_499", 
                    "x_no_of_municip_500_to_1999", "x_no_of_municip_2000_to_9999", 
                    "x_no_of_municip_greater_10000", "x_no_of_cities", "x_ratio_of_urban_inhabitants", 
                    "x_average_salary", "x_unemploymant_rate_1995", "x_unemploymant_rate_1996", 
                    "x_no_of_enterpreneurs_per_1000_inhabitants", "x_no_of_commited_crimes_1995", 
                    "x_no_of_commited_crimes_1996", "x_card_type", "x_card_age_month","x_account_balance", 
                    "x_avg_account_balance","x_transaction_count", "x_transaction_amount", 
                    "x_last_transaction_age_days", "x_prop_old_age_pension", "x_prop_insurance_payment", 
                    "x_prop_sanction_interest","x_prop_household","x_prop_statement",
                    "x_prop_interest_credited", "x_prop_loan_payment", "x_prop_other")

temp <- dplyr::select(temp, y_loan_defaulter, everything())

temp$x_card_type = ifelse(is.na(temp$x_card_type), 'no card', as.character(temp$x_card_type))
temp$x_card_age_month = ifelse(is.na(temp$x_card_age_month), 0, temp$x_card_age_month)
temp$y_loan_defaulter = as.numeric(temp$y_loan_defaulter)

```

We end up with a data set with 38 variables.

## Step 02 - Variable Selection

From this dataset we excluded 6 variables that are redundant, shows no variability on the 682 Loan contract observations or have no applicability for the excersice:

- **x_prop_old_age_pension** (no variation on selected sample)
- **x_district_name** (sample have no enough variability to fit a model)
- **x_region** (sample have no enough variability to fit a model) 
- **x_loan_status** (redundant)
- **x_loan_contract_status** (resundant) 
- **x_prop_sanction_interest** (seems not to be valid for this analysis, as the reason for interest payment in the account is exactly the delinquency in the observatio contact itself)

```{r}

temp <- dplyr::select(temp, -c(x_prop_old_age_pension, 
                               x_district_name, 
                               x_region, 
                               x_loan_status, 
                               x_loan_contract_status, 
                               x_prop_sanction_interest))

```

## Step 03 - Investigating Multicolinearity
With the remaining variables we ran a multicolinearity test to identify additional variables to drop from the model spesification.

```{r}

library(mctest)

vars.quant <- select_if(temp, is.numeric)

imcdiag(vars.quant, temp$y_loan_defaulter)

```

We decided to exclude any variable with a VIF greather than 4.

Below variables were excluded based on the multicolinear presence on them.
- **x_no_of_inhabitants**
- **x_no_of_cities**
- **x_average_salary** 
- **x_unemploymant_rate_1995**
- **x_unemploymant_rate_1996**
- **x_no_of_commited_crimes_1996**
- **x_prop_old_age_pension**
- **x_transaction_count**
- **x_prop_insurance_payment** 
- **x_prop_household**
- **x_prop_statement**
- **x_prop_loan_payment** 
- **x_prop_other**
- **x_loan_status**
- **x_loan_contract_status** 
- **x_prop_sanction_interest**

```{r}

temp <- dplyr::select(temp, -c(x_no_of_inhabitants, 
                               x_no_of_cities,
                               x_average_salary, 
                               x_unemploymant_rate_1995,
                               x_unemploymant_rate_1996, 
                               x_no_of_commited_crimes_1996,
                               x_transaction_count, 
                               x_prop_insurance_payment, 
                               x_prop_household, 
                               x_prop_statement, 
                               x_prop_loan_payment, 
                               x_prop_other))

loan_reg_dataset <- temp

```

Here is the final correlation matrix we got:

```{r}

vars.quant <- select_if(loan_reg_dataset, is.numeric)

imcdiag(vars.quant, loan_reg_dataset$y_loan_defaulter)
mc.plot(vars.quant, loan_reg_dataset$y_loan_defaulter)

corrplot.mixed(cor(vars.quant))

```


## Step 04 - Sample split into Test and Training Data

The available data in Loan Dataset is split into Train and Testing data on the following proportion:

- ***Train Dataset*** (70% xx obs)
- ***Test Dataset*** (30% xx obs)

```{r}

library(caret)

set.seed(12345)
index <- createDataPartition(loan_reg_dataset$y_loan_defaulter, p= 0.7,list = FALSE)

data.train <- loan_reg_dataset[index, ] # base de desenvolvimento: 70%
data.test  <- loan_reg_dataset[-index,] # base de teste: 30%

# Checando se as propor??es das amostras s?o pr?ximas ? base original
prop.table(table(loan_reg_dataset$y_loan_defaulter))
prop.table(table(data.train$y_loan_defaulter))
prop.table(table(data.test$y_loan_defaulter))

```

Both data sets keep the the same proortion for the explainned variable arround 11%.

## Step 05 - Fit the logistic model 

With the final cleanned dataset we got from below steps we fit our Logist Regression:

```{r}

model <- glm(data = data.train, formula = y_loan_defaulter ~ ., 
             family= binomial(link='logit'))

summary(model)

```


# Step 06 - Evaluating the Model Perfromance

We starting this task by making prediction using our model on the x's variables in our Train and Test datasets

```{r}

glm.prob.train <- predict(model, type = "response")
glm.prob.test <- predict(model, newdata = data.test, type= "response")


```


We then evaluate the metrics in the model for Train and Test data:

```{r}

library(hmeasure) 

glm.train <- HMeasure(data.train$y_loan_defaulter, glm.prob.train)
glm.test  <- HMeasure(data.test$y_loan_defaulter, glm.prob.test)

glm.train$metrics
glm.test$metrics

```

Then we look a a boxplot chart to see how well our model split the observation into our explainned variable:

```{r}

library(rms)

boxplot(glm.prob.test ~ data.test$y_loan_defaulter, col= c("red", "green"), 
        horizontal= T)

```

Then we plot the ROC curve of the model:

```{r}

library(pROC)

roc <- roc(data.test$y_loan_defaulter, glm.prob.test)
y1 <- roc$sensitivities
x1 <- 1-roc$specificities

plot(x1, y1,  type="n",
     xlab = "1 - Especificidade", 
     ylab= "Sensitividade")
lines(x1, y1,lwd=3,lty=1, col="purple") 

```

Finnaly we look at the general model accuracy:

```{r}

fitted.results <- ifelse(glm.prob.test > 0.5,1,0)

misClasificError <- mean(fitted.results != data.test$y_loan_defaulter)
print(paste('Accuracy', 1 - misClasificError))

```

# Conclusion
To.do